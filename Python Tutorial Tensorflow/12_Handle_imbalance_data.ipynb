{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Handling Approach (99000 vs 1000)\n",
    "### 1. take 1000 samples from 99000 and discard the rest\n",
    "### 2. over sampling minority class by duplication (1000 x 99)\n",
    "### 3. (BEST METHOD) generate synthetic examples using k-nearest neighbors algorithm (SMOTE: Synthetic Minority Over-sampling technique)\n",
    "### 4. divide the larger sample into multiple samples and train each of them, and then take a majority vote (ensemble method)\n",
    "### 5. penalize majority samples duing loss calculation and give more weight to minority class (Focal Loss)\n",
    "\n",
    "### Examples: churn rate, device failure, cancer prediciton"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\nC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:4524: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().replace(\nC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "%matplotlib inline\n",
    "\n",
    "# import and preprocessing\n",
    "df = pd.read_csv(\"9_Customer_churn.csv\")\n",
    "df.sample(5)\n",
    "df.drop(\"customerID\", axis=\"columns\", inplace = True)\n",
    "pd.to_numeric(df.TotalCharges, errors=\"coerce\")\n",
    "df[pd.to_numeric(df.TotalCharges, errors=\"coerce\").isnull()]\n",
    "df1 = df[df.TotalCharges != \" \"]\n",
    "df1.TotalCharges = pd.to_numeric(df1.TotalCharges)\n",
    "df1.replace(\"No internet service\", \"No\", inplace=True)\n",
    "df1.replace(\"No phone service\", \"No\", inplace=True)\n",
    "df1[\"gender\"].replace({\"Female\": 1, \"Male\": 0}, inplace=True)\n",
    "yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n",
    "                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\n",
    "for col in yes_no_columns:\n",
    "    df1[col].replace({'Yes': 1,'No': 0},inplace=True)\n",
    "df2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])\n",
    "cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n",
    "scaler = MinMaxScaler()\n",
    "df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((5163, 27), (1869, 27))"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# imbalanced dataset\n",
    "count_0, count_1 = df1.Churn.value_counts()\n",
    "df_class_0 = df2[df2[\"Churn\"] == 0]\n",
    "df_class_1 = df2[df2[\"Churn\"] == 1]\n",
    "\n",
    "df_class_0.shape, df_class_1.shape"
   ]
  },
  {
   "source": [
    "## Method 1: Undersampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1869\n",
       "1    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df_class_0_under = df_class_0.sample(count_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "df_test_under.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1495\n",
       "1    1495\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "X = df_test_under.drop(\"Churn\", axis=\"columns\")\n",
    "y = df_test_under[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "y_train.value_counts() # y train has equal sample size because of stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.5725 - accuracy: 0.7120\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7615\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7652\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7659\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7682\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7736\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7739\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7729\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7726\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7763\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7763\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7786\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7786\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7779\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7793\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7819\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7833\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7773\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7806\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7793\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7870\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7870\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7843\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7890\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7863\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7863\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7896\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7926\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7883\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7943\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7960\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7943\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7967\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7963\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7987\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7993\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7967\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8017\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7990\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8030\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8020\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8047\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8037\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8027\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8023\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8067\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8007\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8050\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8023\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8054\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8047\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8064\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8050\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8050\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8070\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8054\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8127\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8097\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8087\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8047\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8151\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8144\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8064\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8134\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8130\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8100\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8144\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8110\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8191\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8114\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8104\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8127\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8120\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8110\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8191\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8174\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8201\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8144\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8154\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8151\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8134\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8144\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8140\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8144\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8191\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8187\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8181\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8154\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8147\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8214\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8151\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8217\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8181\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8174\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8154\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8211\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.7393\n",
      "[0.5586598515510559, 0.7393048405647278]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       374\n",
      "           1       0.75      0.72      0.73       374\n",
      "\n",
      "    accuracy                           0.74       748\n",
      "   macro avg       0.74      0.74      0.74       748\n",
      "weighted avg       0.74      0.74      0.74       748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(26, input_dim=26, activation='relu'),\n",
    "        keras.layers.Dense(15, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds\n",
    "\n",
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "source": [
    "## Method 2: Oversampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(count_0, replace=True) # duplicate samples\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4130\n",
       "1    4130\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "X = df_test_over.drop(\"Churn\", axis=\"columns\")\n",
    "y = df_test_over[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "y_train.value_counts() # y train has equal sample size because of stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7217\n",
      "Epoch 2/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7580\n",
      "Epoch 3/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7656\n",
      "Epoch 4/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7649\n",
      "Epoch 5/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7677\n",
      "Epoch 6/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7749\n",
      "Epoch 7/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7706\n",
      "Epoch 8/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7734\n",
      "Epoch 9/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7720\n",
      "Epoch 10/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7786\n",
      "Epoch 11/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7749\n",
      "Epoch 12/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7760\n",
      "Epoch 13/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7791\n",
      "Epoch 14/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7794\n",
      "Epoch 15/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7763\n",
      "Epoch 16/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7822\n",
      "Epoch 17/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7823\n",
      "Epoch 18/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7839\n",
      "Epoch 19/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7826\n",
      "Epoch 20/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7837\n",
      "Epoch 21/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7839\n",
      "Epoch 22/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7897\n",
      "Epoch 23/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7885\n",
      "Epoch 24/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7892\n",
      "Epoch 25/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7946\n",
      "Epoch 26/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7953\n",
      "Epoch 27/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7961\n",
      "Epoch 28/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7952\n",
      "Epoch 29/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7976\n",
      "Epoch 30/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7967\n",
      "Epoch 31/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7998\n",
      "Epoch 32/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8001\n",
      "Epoch 33/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8004\n",
      "Epoch 34/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7994\n",
      "Epoch 35/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8036\n",
      "Epoch 36/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8024\n",
      "Epoch 37/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8050\n",
      "Epoch 38/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8058\n",
      "Epoch 39/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8052\n",
      "Epoch 40/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8079\n",
      "Epoch 41/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8103\n",
      "Epoch 42/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8084\n",
      "Epoch 43/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8096\n",
      "Epoch 44/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8130\n",
      "Epoch 45/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8114\n",
      "Epoch 46/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8099\n",
      "Epoch 47/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8151\n",
      "Epoch 48/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8139\n",
      "Epoch 49/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8157\n",
      "Epoch 50/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8154\n",
      "Epoch 51/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8145\n",
      "Epoch 52/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8153\n",
      "Epoch 53/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8145\n",
      "Epoch 54/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8189\n",
      "Epoch 55/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8178\n",
      "Epoch 56/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8160\n",
      "Epoch 57/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8214\n",
      "Epoch 58/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8201\n",
      "Epoch 59/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8188\n",
      "Epoch 60/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8201\n",
      "Epoch 61/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8214\n",
      "Epoch 62/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8213\n",
      "Epoch 63/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8208\n",
      "Epoch 64/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8220\n",
      "Epoch 65/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8191\n",
      "Epoch 66/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8255\n",
      "Epoch 67/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8230\n",
      "Epoch 68/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8234\n",
      "Epoch 69/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8237\n",
      "Epoch 70/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8252\n",
      "Epoch 71/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8259\n",
      "Epoch 72/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8238\n",
      "Epoch 73/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8288\n",
      "Epoch 74/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8253\n",
      "Epoch 75/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8260\n",
      "Epoch 76/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8246\n",
      "Epoch 77/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8263\n",
      "Epoch 78/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8283\n",
      "Epoch 79/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8249\n",
      "Epoch 80/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8291\n",
      "Epoch 81/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8283\n",
      "Epoch 82/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8289\n",
      "Epoch 83/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8282\n",
      "Epoch 84/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8320\n",
      "Epoch 85/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8291\n",
      "Epoch 86/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8317\n",
      "Epoch 87/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8269\n",
      "Epoch 88/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8288\n",
      "Epoch 89/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8324\n",
      "Epoch 90/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8317\n",
      "Epoch 91/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8309\n",
      "Epoch 92/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8343\n",
      "Epoch 93/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8331\n",
      "Epoch 94/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8351\n",
      "Epoch 95/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8363\n",
      "Epoch 96/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8356\n",
      "Epoch 97/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8373\n",
      "Epoch 98/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8343\n",
      "Epoch 99/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8367\n",
      "Epoch 100/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8341\n",
      "65/65 [==============================] - 0s 993us/step - loss: 0.4864 - accuracy: 0.7749\n",
      "[0.48638203740119934, 0.7749273777008057]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      1033\n",
      "           1       0.74      0.84      0.79      1033\n",
      "\n",
      "    accuracy                           0.77      2066\n",
      "   macro avg       0.78      0.77      0.77      2066\n",
      "weighted avg       0.78      0.77      0.77      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)\n",
    "# better than 1"
   ]
  },
  {
   "source": [
    "## Method 3: SMOTE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4130\n",
       "1    4130\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X = df2.drop(\"Churn\", axis=\"columns\")\n",
    "y = df2[\"Churn\"]\n",
    "\n",
    "smote = SMOTE(sampling_strategy=\"minority\")\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "259/259 [==============================] - 1s 2ms/step - loss: 0.5219 - accuracy: 0.7458\n",
      "Epoch 2/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7736\n",
      "Epoch 3/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7774\n",
      "Epoch 4/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7814\n",
      "Epoch 5/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7855\n",
      "Epoch 6/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7889\n",
      "Epoch 7/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7941\n",
      "Epoch 8/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7977\n",
      "Epoch 9/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8002\n",
      "Epoch 10/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8007\n",
      "Epoch 11/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8036\n",
      "Epoch 12/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8065\n",
      "Epoch 13/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8099\n",
      "Epoch 14/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8107\n",
      "Epoch 16/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8115\n",
      "Epoch 17/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8145\n",
      "Epoch 18/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8161\n",
      "Epoch 19/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8189\n",
      "Epoch 20/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8196\n",
      "Epoch 21/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8215\n",
      "Epoch 22/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8222\n",
      "Epoch 23/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8254\n",
      "Epoch 24/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8255\n",
      "Epoch 25/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8249\n",
      "Epoch 26/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8275\n",
      "Epoch 27/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8249\n",
      "Epoch 28/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8274\n",
      "Epoch 29/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8312\n",
      "Epoch 30/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8272\n",
      "Epoch 31/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8288\n",
      "Epoch 32/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8303\n",
      "Epoch 33/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8299\n",
      "Epoch 34/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8312\n",
      "Epoch 35/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8292\n",
      "Epoch 36/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8339\n",
      "Epoch 37/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8360\n",
      "Epoch 38/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8322\n",
      "Epoch 39/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8335\n",
      "Epoch 40/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8347\n",
      "Epoch 41/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8349\n",
      "Epoch 42/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8362\n",
      "Epoch 43/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8343\n",
      "Epoch 44/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8346\n",
      "Epoch 45/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8362\n",
      "Epoch 46/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8370\n",
      "Epoch 47/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8335\n",
      "Epoch 48/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8361\n",
      "Epoch 49/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8395\n",
      "Epoch 50/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8425\n",
      "Epoch 51/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8419\n",
      "Epoch 52/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8391\n",
      "Epoch 53/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8418\n",
      "Epoch 54/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8407\n",
      "Epoch 55/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8433\n",
      "Epoch 56/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8425\n",
      "Epoch 57/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8430\n",
      "Epoch 58/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8430\n",
      "Epoch 59/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8435\n",
      "Epoch 60/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8404\n",
      "Epoch 61/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8424\n",
      "Epoch 62/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8430\n",
      "Epoch 63/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8456\n",
      "Epoch 64/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8475\n",
      "Epoch 65/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8435\n",
      "Epoch 66/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8441\n",
      "Epoch 67/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8478\n",
      "Epoch 68/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8455\n",
      "Epoch 69/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8432\n",
      "Epoch 70/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8476\n",
      "Epoch 71/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8458\n",
      "Epoch 72/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8467\n",
      "Epoch 73/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8513\n",
      "Epoch 74/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8469\n",
      "Epoch 75/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8462\n",
      "Epoch 76/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8489\n",
      "Epoch 77/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8470\n",
      "Epoch 78/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8492\n",
      "Epoch 79/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8448\n",
      "Epoch 80/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8470\n",
      "Epoch 81/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8473\n",
      "Epoch 82/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8539\n",
      "Epoch 83/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8479\n",
      "Epoch 84/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8507\n",
      "Epoch 85/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8513\n",
      "Epoch 86/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8465\n",
      "Epoch 87/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8469\n",
      "Epoch 88/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8518\n",
      "Epoch 89/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8495\n",
      "Epoch 90/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8508\n",
      "Epoch 91/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8498\n",
      "Epoch 92/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8496\n",
      "Epoch 93/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8535\n",
      "Epoch 94/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8495\n",
      "Epoch 95/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8506\n",
      "Epoch 96/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8521\n",
      "Epoch 97/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8478\n",
      "Epoch 98/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8516\n",
      "Epoch 99/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8528\n",
      "Epoch 100/100\n",
      "259/259 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8524\n",
      "65/65 [==============================] - 0s 977us/step - loss: 0.4253 - accuracy: 0.8074\n",
      "[0.4252845048904419, 0.8073571920394897]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80      1033\n",
      "           1       0.78      0.85      0.82      1033\n",
      "\n",
      "    accuracy                           0.81      2066\n",
      "   macro avg       0.81      0.81      0.81      2066\n",
      "weighted avg       0.81      0.81      0.81      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "source": [
    "## Method 4: Ensemble | undersampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4130\n",
       "1    1495\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "X = df2.drop(\"Churn\", axis=\"columns\")\n",
    "y = df2[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.762541806020067"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "4130 / 1495 # divide to approx 3 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.5007e-06 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.2762e-06 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.0742e-06 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.8904e-06 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.7178e-06 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.5626e-06 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.4184e-06 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.2864e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.1623e-06 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.0487e-06 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.9406e-06 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.8429e-06 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.7501e-06 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6637e-06 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.5839e-06 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.5069e-06 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4380e-06 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.3710e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.3089e-06 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.2506e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.1944e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.1426e-06 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0926e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0463e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0022e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.6077e-07 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.2065e-07 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.8362e-07 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.4729e-07 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.1359e-07 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.8159e-07 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.5139e-07 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.2224e-07 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9471e-07 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.6852e-07 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.4379e-07 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.1932e-07 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.9664e-07 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.7521e-07 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5443e-07 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3466e-07 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1586e-07 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9776e-07 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.7995e-07 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.6367e-07 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.4729e-07 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.3202e-07 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.1705e-07 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.0276e-07 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.8917e-07 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.7611e-07 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.6393e-07 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.5162e-07 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.4018e-07 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.2914e-07 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.1838e-07 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.0782e-07 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.9822e-07 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.8858e-07 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.7941e-07 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.7062e-07 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.6194e-07 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.5385e-07 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.4600e-07 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.3813e-07 - accuracy: 1.0000\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 14.1507 - accuracy: 0.2658\n",
      "[14.150733947753906, 0.26581379771232605]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1033\n",
      "           1       0.27      1.00      0.42       374\n",
      "\n",
      "    accuracy                           0.27      1407\n",
      "   macro avg       0.13      0.50      0.21      1407\n",
      "weighted avg       0.07      0.27      0.11      1407\n",
      "\n",
      "Epoch 1/100\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "47/47 [==============================] - 1s 2ms/step - loss: 0.6506 - accuracy: 0.6161\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.2485e-04 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.4405e-04 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.2166e-04 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.3841e-04 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.7625e-04 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.2947e-04 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.9380e-04 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6519e-04 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4246e-04 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.2425e-04 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0890e-04 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.6402e-05 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.5845e-05 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.6830e-05 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9224e-05 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.2461e-05 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.6801e-05 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1670e-05 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.7315e-05 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.3433e-05 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.9935e-05 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.6889e-05 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.4077e-05 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.1585e-05 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.9375e-05 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.7364e-05 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.5515e-05 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.3825e-05 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.2334e-05 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.0929e-05 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.9646e-05 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.8473e-05 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.7395e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6397e-05 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.5473e-05 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4636e-05 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.3836e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.3098e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.2420e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.1779e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.1177e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0628e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0108e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.6150e-06 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 9.1547e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.7332e-06 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 8.3303e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.9496e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.5900e-06 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 7.2521e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.9264e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.6335e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.3385e-06 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 6.0786e-06 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.8194e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.5787e-06 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.3476e-06 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 5.1302e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.9313e-06 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.7233e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.5424e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.3597e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.1916e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.0272e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.8739e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.7276e-06 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.5868e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.4504e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.3266e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.2007e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.0868e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.9732e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.8666e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.7636e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.6635e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.5702e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.4810e-06 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.3926e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.3097e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.2300e-06 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.1538e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.0802e-06 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.0109e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.9418e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.8789e-06 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.8155e-06 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.7554e-06 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6969e-06 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6408e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.5881e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.5361e-06 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4863e-06 - accuracy: 1.0000\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 13.2259 - accuracy: 0.2658\n",
      "[13.225852012634277, 0.26581379771232605]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1033\n",
      "           1       0.27      1.00      0.42       374\n",
      "\n",
      "    accuracy                           0.27      1407\n",
      "   macro avg       0.13      0.50      0.21      1407\n",
      "weighted avg       0.07      0.27      0.11      1407\n",
      "\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df3 = X_train.copy()\n",
    "df3['Churn'] = y_train\n",
    "df3_class0 = df3[df3.Churn==0]\n",
    "df3_class1 = df3[df3.Churn==1]\n",
    "\n",
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('Churn', axis='columns')\n",
    "    y_train = df_train.Churn\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 0, 1495)\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n",
    "\n",
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 1495, 2990)\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n",
    "\n",
    "X_train, y_train = get_train_batch(df3_class0, df3_class1, 2990, 4130)\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if n_ones>1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      0.00      0.00      1033\n           1       0.27      1.00      0.42       374\n\n    accuracy                           0.27      1407\n   macro avg       0.63      0.50      0.21      1407\nweighted avg       0.80      0.27      0.11      1407\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final, zero_division=True))"
   ]
  }
 ]
}