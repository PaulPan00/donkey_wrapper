{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Retrain an existing model for new data\n",
    "- ### freeze existing layers to classify existing data omitting last layer(weight don't change)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import pathlib\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# load the pre-trained model\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "IMAGE_SHAPE + (3, ) # add rgb layers\n",
    "\n",
    "classifier = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))])"
   ]
  },
  {
   "source": [
    "## Predict a goldfish using this existing model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "gold_fish = Image.open(requests.get(\"https://raw.githubusercontent.com/codebasics/deep-learning-keras-tf-tutorial/master/18_transfer_learning/goldfish.jpg\", stream=True).raw).resize(IMAGE_SHAPE)\n",
    "\n",
    "gold_fish = np.array(gold_fish) / 255.0\n",
    "gold_fish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'goldfish'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "result = classifier.predict(gold_fish[np.newaxis, ...])\n",
    "\n",
    "image_labels = []\n",
    "with open(\"16_Image_net_labels.txt\", \"r\") as f:\n",
    "    image_labels = f.read().splitlines()\n",
    "image_labels[np.argmax(result)]"
   ]
  },
  {
   "source": [
    "## Load new data and retrain the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, split and preprocessing\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}\n",
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}\n",
    "X, y = [], []\n",
    "for name, imgs in flowers_images_dict.items():\n",
    "    for img in imgs:\n",
    "        img = cv2.imread(str(img))\n",
    "        resized_img = cv2.resize(img, (224, 224))\n",
    "        X.append(resized_img)\n",
    "        y.append(flowers_labels_dict[name])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train, X_test = X_train / 255, X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[795 880 795]\nshower curtain umbrella shower curtain\nroses daisy dandelion\n"
     ]
    }
   ],
   "source": [
    "# try to use classifier to predict our new dataset, way off\n",
    "print(np.argmax(classifier.predict(np.array([X[0], X[1], X[2]])), axis=1))\n",
    "print(image_labels[795], image_labels[880], image_labels[795])\n",
    "\n",
    "key_list = list(flowers_labels_dict.keys())\n",
    "val_list = list(flowers_labels_dict.values())\n",
    "print(key_list[val_list.index(0)], key_list[val_list.index(1)], key_list[val_list.index(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the existing model\n",
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nkeras_layer_4 (KerasLayer)   (None, 1280)              2257984   \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 6405      \n=================================================================\nTotal params: 2,264,389\nTrainable params: 6,405\nNon-trainable params: 2,257,984\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    pretrained_model_without_top_layer,\n",
    "    keras.layers.Dense(5),\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.2027 - accuracy: 0.9440\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1796 - accuracy: 0.9549\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1652 - accuracy: 0.9586\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1455 - accuracy: 0.9669\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1306 - accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1186 - accuracy: 0.9775\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.1092 - accuracy: 0.9807\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.0999 - accuracy: 0.9833\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.0901 - accuracy: 0.9858\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.0807 - accuracy: 0.9876\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x130ba4175e0>"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# very fast training time and good accuracy\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification Report: \n               precision    recall  f1-score   support\n\n           0       0.85      0.86      0.86       176\n           1       0.78      0.92      0.84       154\n           2       0.95      0.87      0.91       226\n           3       0.90      0.87      0.88       150\n           4       0.88      0.86      0.87       212\n\n    accuracy                           0.87       918\n   macro avg       0.87      0.88      0.87       918\nweighted avg       0.88      0.87      0.87       918\n\n"
     ]
    }
   ],
   "source": [
    "# very good prediction data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [np.argmax(x) for x in y_pred]\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}