{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# RNN mainly used for natual language processing\n",
    "<br>\n",
    "\n",
    "## Why not ANN?\n",
    "- ### Variable size of neurons in a layer\n",
    "- ### Too much computation\n",
    "- ### Parameters are not shared (can't switch sentence sequence)\n",
    "<br>\n",
    "\n",
    "## Named Entity Recognition (many input to many output)\n",
    "- ### Finds out the entity and mark it using ones and zeros\n",
    "- ### Only one hidden layer, looping through this hidden layer (can have multiple hidden layers)\n",
    "<br>\n",
    "\n",
    "## Sentiment Analysis (many input to one output)\n",
    "- ### Input a sentence, output a review score\n",
    "- ### Provide a single word/note, output a poem/song"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Vanishing Gradients will make smaller weights even smaller (make learning very slow)\n",
    "### Exploding Gradients will make larger weights even larger\n",
    "<br><br>\n",
    "### Traditional RNN does not account for relationships for words that are far apart from each other (short term memory)\n",
    "### GRU and LSTM accounts for this shorter memory problem\n",
    "<img src=\"https://media.discordapp.net/attachments/763819251249184789/858042335228854302/image.png\" width=700>\n",
    "\n",
    "## LSTM:\n",
    "- ### Store important words in a long term memory, also keep the short term memory. Forget old keyword (Forget Gate) after a period and record new keywords (Input Gate)\n",
    "- ### More gate, more accurate but takes longer\n",
    "<img src=\"https://media.discordapp.net/attachments/763819251249184789/858189868516507668/image.png\" width=700>\n",
    "\n",
    "<br>\n",
    "\n",
    "## GRU (Gated Recurrent Units):\n",
    "- ### Combined long term and short term memory\n",
    "- ### More efficient, 2 gates (reset, update)\n",
    "<img src=\"https://media.discordapp.net/attachments/763819251249184789/858192984259690506/image.png\" width=700>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Bidirectional RNN\n",
    "-  ### Goes backward to determine previous keywords using context\n",
    "\n",
    "<br>\n",
    "\n",
    "## Preprocessing (cvt words to numbers)\n",
    "- ### Assign unique numbers to words. Cons: ramdom and don't record relationships between words\n",
    "- ### One hot encoding. Cons: No relationships, computation inefficient\n",
    "- ### Word embedding: convert words to vectors with different features (automatic process) (TF-IDF, Word2Vec)\n",
    "<img src=\"https://media.discordapp.net/attachments/763819251249184789/858197391496577054/image.png\" width=700>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Supervised learning (not popular)\n",
    "- ### Take a NLP problem and tru to solve it, get word embeddings as side effect\n",
    "- ### Come up with a embedding size (4, 10, 300) that becomes matrix E\n",
    "- ### Full process (also need padding):\n",
    "<img src=\"https://cdn.discordapp.com/attachments/763819251249184789/858199864655609856/image.png\" width=700>\n",
    "- ### Eventually word with similar meanings will have similar feature vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[13, 34,  0],\n",
       "       [42, 28,  0],\n",
       "       [18,  8,  0],\n",
       "       [16, 46, 46],\n",
       "       [46, 19,  8],\n",
       "       [12, 34,  0],\n",
       "       [ 2, 19,  3],\n",
       "       [48, 33,  0],\n",
       "       [48, 20,  0],\n",
       "       [38, 17,  0]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "reviews = ['nice food',\n",
    "        'amazing restaurant',\n",
    "        'too good',\n",
    "        'just loved it!',\n",
    "        'will go again',\n",
    "        'horrible food',\n",
    "        'never go there',\n",
    "        'poor service',\n",
    "        'poor quality',\n",
    "        'needs improvement']\n",
    "\n",
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])\n",
    "\n",
    "\n",
    "vocab_size = 50\n",
    "\n",
    "enc_rev = [one_hot(d, vocab_size) for d in reviews]\n",
    "max_len = 3\n",
    "padded_rev = pad_sequences(enc_rev, maxlen=max_len, padding=\"post\") # added padding\n",
    "\n",
    "X = padded_rev\n",
    "y = sentiment\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 4, input_length=max_len, name=\"embedding\"),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.6890 - accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.8000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.8000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.8000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.8000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eb6ac3b9d0>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6203 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X, y)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# get embeddings\n",
    "w = model.get_layer(\"embedding\").get_weights()[0]\n",
    "len(w)"
   ]
  }
 ]
}